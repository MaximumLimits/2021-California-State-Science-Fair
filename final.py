import tensorflow as tf
import numpy as np
from images import load_images
tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)
X_train, y_train, X_test, y_test, X_val, y_val = load_images(shuffle_before=True, num_augments=4)  # 2

# data_gen_args = dict(rotation_range=90,
#                      width_shift_range=0.1,
#                      height_shift_range=0.1,
#                      zoom_range=0.2)
# image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)
# X_train, y_train = image_datagen.flow(X_train, y_train, batch_size=X_train.shape[0])[0]
# X_test, y_test = image_datagen.flow(X_test, y_test, batch_size=X_test.shape[0])[0]
# X_val, y_val = image_datagen.flow(X_val, y_val, batch_size=X_val.shape[0])[0]


input_shape = X_train.shape[1:]

disable_debug_info = False
if disable_debug_info:
    import os
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'


def create_and_train_MXnet(return_results=False, save_history=False, save_file='TARnet.hdf5'):

    initializer = tf.keras.initializers.VarianceScaling(2)

    layers = [
        tf.keras.layers.Conv2D(64, 3, 1, 'same', input_shape=input_shape, kernel_initializer=initializer, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(64, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),

        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.BatchNormalization(),

        tf.keras.layers.Conv2D(128, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(128, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),

        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.BatchNormalization(),

        tf.keras.layers.Conv2D(256, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(256, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),

        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.BatchNormalization(),

        tf.keras.layers.Conv2D(128, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv2D(64, 3, 1, 'same', kernel_initializer=initializer, activation='relu'),

        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.BatchNormalization(),

        tf.keras.layers.Conv2D(6, 3, 1, 'same', kernel_initializer=initializer),  # revised
        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Activation('softmax')
    ]
    model = tf.keras.models.Sequential(layers)

    train_loss = []
    val_loss = []
    train_acc = []
    val_acc = []

    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)
    save_best_model = tf.keras.callbacks.ModelCheckpoint(save_file, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True)

    first_learning_rate = 2.26e-4
    second_learning_rate = 3.35e-5

    optimizer = tf.keras.optimizers.RMSprop()
    model.compile(optimizer, loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])

    epoch_zero_train_loss, epoch_zero_train_acc = model.evaluate(X_train, y_train, verbose=0)
    epoch_zero_val_loss, epoch_zero_val_acc = model.evaluate(X_val, y_val, verbose=0)
    train_loss.append(epoch_zero_train_loss)
    val_loss.append(epoch_zero_val_loss)
    train_acc.append(epoch_zero_train_acc)
    val_acc.append(epoch_zero_val_acc)
    print('Before training')
    print(f'1768/1768 - ?s - loss: {epoch_zero_train_loss:.4f} - accuracy: {epoch_zero_train_acc:.4f} - val_loss: {epoch_zero_val_loss:.4f} - val_accuracy: {epoch_zero_val_acc:.4f}')

    print(f'\nFirst Training Session | lr: {first_learning_rate:.2e}')
    optimizer.learning_rate = first_learning_rate
    history = model.fit(X_train, y_train, 26, epochs=16, validation_data=(X_val, y_val), verbose=2, callbacks=[early_stopping, save_best_model])
    train_loss.extend(history.history['loss'])
    val_loss.extend(history.history['val_loss'])
    train_acc.extend(history.history['accuracy'])
    val_acc.extend(history.history['val_accuracy'])

    print(f'\nSecond Training Session | lr: {second_learning_rate:.2e}')
    model.load_weights(save_file)
    optimizer.learning_rate = second_learning_rate
    history = model.fit(X_train, y_train, 26, epochs=14, validation_data=(X_val, y_val), verbose=2, callbacks=[early_stopping, save_best_model])
    train_loss.extend(history.history['loss'])
    val_loss.extend(history.history['val_loss'])
    train_acc.extend(history.history['accuracy'])
    val_acc.extend(history.history['val_accuracy'])

    model.load_weights(save_file)
    test_results = model.evaluate(X_test, y_test)

    if save_history:
        train_loss = np.asarray(train_loss)
        train_acc = np.asarray(train_acc)
        val_loss = np.asarray(val_loss)
        val_acc = np.asarray(val_acc)
        np.save(f'training_losses/MXnet.npy', train_loss)
        np.save(f'training_accuracies/MXnet.npy', train_acc)
        np.save(f'validation_losses/MXnet.npy', val_loss)
        np.save(f'validation_accuracies/MXnet.npy', val_acc)

    if return_results:
        return test_results[1]

    import matplotlib.pyplot as plt

    fig, axs = plt.subplots(2, 1, constrained_layout=True)

    axs[0].plot(train_loss, label='Train loss')
    axs[0].plot(val_loss, label='Validation loss')
    axs[0].set_title('Train and Validation Losses of MXnet', fontsize=18)
    axs[0].set_xlabel('Epoch')
    axs[0].set_ylabel('Loss')
    axs[0].legend(loc='upper right')
    axs[0].set_xlim(0, len(train_acc))

    axs[1].plot(train_acc, label='Train accuracy')
    axs[1].plot(val_acc, label='Validation Accuracy')
    axs[1].set_title('Train and Validation Accuracies of MXnet', fontsize=18)
    axs[1].set_xlabel('Epoch')
    axs[1].set_ylabel('Accuracy')
    axs[1].hlines(0.85, 0, len(train_acc), label='85% Accuracy')
    axs[1].legend(loc='lower right')

    plt.xlim(0, len(train_acc))

    plt.show()


def check_mean_accuracy(num_models=7):
    accuracies = []
    for _ in range(num_models):
        global X_train, y_train, X_test, y_test, X_val, y_val, input_shape
        X_train, y_train, X_test, y_test, X_val, y_val = load_images(shuffle_before=True)
        input_shape = X_train.shape[1:]
        accuracies.append(create_and_train_MXnet(return_results=True))

    print(np.mean(accuracies))


'''
Before training
1768/1768 - ?s - loss: 1.8432 - accuracy: 0.0650 - val_loss: 1.8463 - val_accuracy: 0.0610

First Training Session | lr: 2.26e-04
Train on 1768 samples, validate on 328 samples
Epoch 1/16
1768/1768 - 9s - loss: 1.3536 - accuracy: 0.5407 - val_loss: 1.4690 - val_accuracy: 0.4421
Epoch 2/16
1768/1768 - 7s - loss: 1.1438 - accuracy: 0.6448 - val_loss: 1.3416 - val_accuracy: 0.5122
Epoch 3/16
1768/1768 - 7s - loss: 1.0259 - accuracy: 0.6719 - val_loss: 1.4115 - val_accuracy: 0.5335
Epoch 4/16
1768/1768 - 7s - loss: 0.9175 - accuracy: 0.7093 - val_loss: 1.1408 - val_accuracy: 0.5793
Epoch 5/16
1768/1768 - 7s - loss: 0.8375 - accuracy: 0.7262 - val_loss: 0.9135 - val_accuracy: 0.6890
Epoch 6/16
1768/1768 - 7s - loss: 0.7773 - accuracy: 0.7506 - val_loss: 0.8095 - val_accuracy: 0.7378
Epoch 7/16
1768/1768 - 7s - loss: 0.7125 - accuracy: 0.7783 - val_loss: 0.8090 - val_accuracy: 0.7317
Epoch 8/16
1768/1768 - 7s - loss: 0.6434 - accuracy: 0.7981 - val_loss: 0.6352 - val_accuracy: 0.8140
Epoch 9/16
1768/1768 - 7s - loss: 0.5759 - accuracy: 0.8241 - val_loss: 0.6376 - val_accuracy: 0.7957
Epoch 10/16
1768/1768 - 7s - loss: 0.5405 - accuracy: 0.8388 - val_loss: 0.5540 - val_accuracy: 0.8232
Epoch 11/16
1768/1768 - 7s - loss: 0.5009 - accuracy: 0.8518 - val_loss: 0.5099 - val_accuracy: 0.8354
Epoch 12/16
1768/1768 - 7s - loss: 0.4444 - accuracy: 0.8744 - val_loss: 0.5089 - val_accuracy: 0.8323
Epoch 13/16
1768/1768 - 7s - loss: 0.3938 - accuracy: 0.8925 - val_loss: 0.5179 - val_accuracy: 0.8232
Epoch 14/16
1768/1768 - 7s - loss: 0.3597 - accuracy: 0.8959 - val_loss: 0.6661 - val_accuracy: 0.7744
Epoch 15/16
1768/1768 - 7s - loss: 0.3578 - accuracy: 0.9005 - val_loss: 0.4994 - val_accuracy: 0.8415
Epoch 16/16
1768/1768 - 7s - loss: 0.2983 - accuracy: 0.9219 - val_loss: 0.4585 - val_accuracy: 0.8293

Second Training Session | lr: 3.35e-05

Train on 1768 samples, validate on 328 samples
Epoch 1/14
1768/1768 - 7s - loss: 0.1528 - accuracy: 0.9734 - val_loss: 0.3382 - val_accuracy: 0.9055
Epoch 2/14
1768/1768 - 7s - loss: 0.1420 - accuracy: 0.9706 - val_loss: 0.3293 - val_accuracy: 0.9024
Epoch 3/14
1768/1768 - 7s - loss: 0.1204 - accuracy: 0.9859 - val_loss: 0.3373 - val_accuracy: 0.9116
Epoch 4/14
1768/1768 - 7s - loss: 0.1142 - accuracy: 0.9847 - val_loss: 0.3381 - val_accuracy: 0.9024
Epoch 5/14
1768/1768 - 7s - loss: 0.1007 - accuracy: 0.9893 - val_loss: 0.3132 - val_accuracy: 0.9116
Epoch 6/14
1768/1768 - 7s - loss: 0.0946 - accuracy: 0.9898 - val_loss: 0.3271 - val_accuracy: 0.8963
Epoch 7/14
1768/1768 - 7s - loss: 0.0919 - accuracy: 0.9915 - val_loss: 0.3022 - val_accuracy: 0.9146
Epoch 8/14
1768/1768 - 7s - loss: 0.0771 - accuracy: 0.9949 - val_loss: 0.3093 - val_accuracy: 0.9207
Epoch 9/14
1768/1768 - 7s - loss: 0.0678 - accuracy: 0.9949 - val_loss: 0.2850 - val_accuracy: 0.9177
Epoch 10/14
1768/1768 - 7s - loss: 0.0712 - accuracy: 0.9921 - val_loss: 0.2919 - val_accuracy: 0.9207
Epoch 11/14
1768/1768 - 7s - loss: 0.0653 - accuracy: 0.9966 - val_loss: 0.3103 - val_accuracy: 0.8994
Epoch 12/14
1768/1768 - 7s - loss: 0.0607 - accuracy: 0.9960 - val_loss: 0.3059 - val_accuracy: 0.9177

431/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================]
 - 1s 1ms/sample - loss: 0.3173 - accuracy: 0.8770
 
 
 
 
 
 
 
 
 
 
 
 
'''

create_and_train_MXnet()
